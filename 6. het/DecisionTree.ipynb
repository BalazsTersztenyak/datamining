{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zWSWs6xlqzLx"
   },
   "outputs": [],
   "source": [
    "# importing needed libraries\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AbmCPyMcqzLx"
   },
   "outputs": [],
   "source": [
    "# reading the data to pandas dataframe\n",
    "url=\"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "\n",
    "# creat X and y as numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ymqdLKCdqzLx",
    "outputId": "05e5ec80-7c38-4028-dc9f-dd1e2016338a"
   },
   "outputs": [],
   "source": [
    "# Check the data we read (head) and the numpy array we created(shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset to train and \n",
    "X_train, X_test, y_train, y_test ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Decision Tree Classifier with max_depth=3\n",
    "# Fit the model to the training data\n",
    "# Calculate the accuracy of the model on the test data\n",
    "start_time = time.time()\n",
    "classifier = \n",
    "\n",
    "score = \n",
    "\n",
    "print(f'Score: {score}')\n",
    "print(f'Train time:{time.time()-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Decision Tree Classifier with max_depth=3 and criterion='entropy'\n",
    "# Fit the model to the training data\n",
    "# Calculate the accuracy of the model on the test data\n",
    "start_time = time.time()\n",
    "classifier = \n",
    "\n",
    "score = \n",
    "print(f'Score: {score}')\n",
    "print(f'Train time:{time.time()-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the decision tree\n",
    "tree.plot_tree(classifier)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Forest of 10 Trees\n",
    "# And train it on different set of the train data\n",
    "start_time = time.time()\n",
    "\n",
    "forest = []\n",
    "for i in range(10):\n",
    "    # Create a train set for each tree\n",
    "    y_temp = np.expand_dims(y_train.copy(),axis = -1)\n",
    "    X_temp = X_train.copy()\n",
    "    # Remove one feature from the train set\n",
    "    X_temp = np.delete(X_temp, i%X_temp.shape[-1],1)\n",
    "    train_set = np.concatenate((X_temp, y_temp), axis = 1)\n",
    "    random.shuffle(train_set)\n",
    "    train_set = train_set[:int(0.9*len(train_set))]\n",
    "    y_temp = train_set[:,-1:]\n",
    "    X_temp = train_set[:,:-1]\n",
    "    \n",
    "    # Create a Decision Tree Classifier with max_depth=3\n",
    "    \n",
    "    # Fit the model to the training data\n",
    "    \n",
    "    # Add the model to the forest\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the Predict function\n",
    "def ForestPredict(x):\n",
    "    # Create a variable to store the predictions\n",
    "    y_preds = []\n",
    "    \n",
    "    # Iterate over the forest and predict the label for each tree\n",
    "    for i,tre in enumerate(forest):\n",
    "        # Remove a feature from the set\n",
    "        t = x.copy()\n",
    "        t = np.delete(t, i%t.shape[-1])\n",
    "        # Add the prediction to the list of predictions\n",
    "        \n",
    "    \n",
    "    y_preds = np.array(y_preds, dtype = int)\n",
    "    counts = np.bincount(y_preds)\n",
    "    return np.argmax(counts)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8051948051948052"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the accuracy of the model on the test data\n",
    "y_pred = []\n",
    "for X in X_test:\n",
    "    y_pred.append(ForestPredict(X))\n",
    "y_pred = np.array(y_pred)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_estimators = [2,10,200]\n",
    "criterion = ['gini', 'entropy']\n",
    "max_features =['auto']\n",
    "max_depth = [5,10,15]\n",
    "min_samples_split = [2,5,50]\n",
    "min_samples_leaf = [1,4,20]\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid ={\n",
    "        'n_estimators': n_estimators,\n",
    "        'criterion': criterion,\n",
    "        'max_features': max_features,\n",
    "        'max_depth': max_depth,\n",
    "        'min_samples_split':min_samples_split,\n",
    "        'bootstrap': bootstrap\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trains time: 79.5402045249939\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(estimator = rf, \n",
    "                           param_distributions = random_grid,\n",
    "                           n_iter = 10, \n",
    "                           cv = 10, \n",
    "                           random_state=42)\n",
    "rf_random.fit(X_train,y_train)\n",
    "\n",
    "print(f'Trains time: {time.time()-start_time}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf_random.best_estimator_.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "6.pactice.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
